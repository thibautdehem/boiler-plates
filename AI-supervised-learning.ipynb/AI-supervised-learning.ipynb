{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-991316fbca1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-65540c512151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read and get some insights on the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"your_file.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n/d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read and get some insights on the DataFrame\n",
    "df = pd.read_csv(\"your_file.csv\", index_col=0,  sep=';', skiprows=[1], na_values=['n/d'], parse_dates=True)\n",
    "df.head()\n",
    "df.tail()\n",
    "df.describe()\n",
    "df.info()\n",
    "df.count()\n",
    "\n",
    "# Search correlation between some input (X) columns and the output (Y) column\n",
    "\n",
    "df.groupby(\"one_of_the_X_column\")[\"y_column\"].mean().plot(kind=\"bar\")\n",
    "\n",
    "# Add a new column to search on basis of different criteria\n",
    "df['new column'] = address "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT - PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0a1eb9a7eed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y_column\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"any_other_unecessary_column\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y_column\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Replace wrong and missing (NaN) values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Select only the data that matters (boolea indexing, pivot, merge, add column)\n",
    "df['new-column'] = pd.your_list\n",
    "new_def = df['X_Column'] > 50\n",
    "\n",
    "\n",
    "# Convert into Numpy arrays/ Three possible methods: X = df[[\"x\"]] / .values / .to_numpy()  \n",
    "X = df.drop([\"Y_column\", \"any_other_unecessary_column\"], axis=1).to_numpy()\n",
    "y = df[\"Y_column\"].to_numpy() \n",
    "\n",
    "\n",
    "# Replace wrong and missing (NaN) values \n",
    "X = X.replace([wrong_value], np.nan)\n",
    "df.isna().sum()\n",
    "df = df.fillna(value=-1)  \n",
    "\n",
    "# Treat missing values with 'most_frequent' / 'nearest neigh' / 'constant' / 'mean' / 'meadian'\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "X[\"column_to_reshape\"] = imp.fit_transform(X[\"column_to_reshape\"].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Convert categorical variables + Rescale into numpy Array\n",
    "categories = X.dtypes == object\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OR from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tf = make_column_transformer((OneHotEncoder(sparse=False), categories), \n",
    "                             (StandardScaler(), ~categories),\n",
    "                             remainder=\"passthrough\")\n",
    "X_new = tf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT - CLASSIFIER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9f89fb0f566d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Choose your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Choose your model\n",
    "\n",
    "Method to choose: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "Some models:\n",
    "    \n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(random_state=0, tol=1e-5)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regression = LogisticRegression()\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random = RandomForestClassifier(n_estimators=100)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Split the datae\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Fit and run the results\n",
    "my_model.fit(X_train, y_train)\n",
    "print(my_model.predict(X_train[:5]))\n",
    "print(y_train[:5])\n",
    "print(my_model.predict_proba(X_train[:5]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT - EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Scores and confusion martix for various models\n",
    "print(\"Score =\",my_model.score(X_test, y_test))\n",
    "print(\"Accuracy =\",accuracy_score(y_test, dummy.predict(X_test)))\n",
    "print(\"Precision =\", precision_score(y_test, my_model.predict(X_test)))\n",
    "print(\"Recall =\", recall_score(y_test, my_model.predict(X_test)))\n",
    "print(\"F =\", fbeta_score(y_test, clf.predict(X_test), beta=1))\n",
    "print(\"ROC AUC =\", roc_auc_score(y_test, my_model.predict_proba(X_test)[:, 1]))\n",
    "fpr, tpr, thresholds = roc_curve(y_train, my_model.predict_proba(X_train)[:, 1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n",
    "print(\"Confusion Matrix =\",confusion_matrix(y_train, my_model.predict(X_train)))\n",
    "print(classification_report(y_train, my_model.predict(X_train)))\n",
    "\n",
    "# Get Feature Importance from the classifier\n",
    "feature_importance = my_model.feature_importances_\n",
    "print (feature_importance)\n",
    "feat_importances = pd.Series(feature_importance, index=df.columns)\n",
    "feat_importances = feat_importances.nlargest(19)\n",
    "feat_importances.plot(kind='barh' , figsize=(10,10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT - REGRESSOR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-87030000a2c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build X,y matrices and split them in train/test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Build X,y matrices and split them in train/test\n",
    "X = df[[\"x\"]]\n",
    "y = df[[\"y\"]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Choose and train the model\n",
    "# See all models here: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh_regression = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "# Compute Prediction\n",
    "y_pred_train = my_model.predict(X_train)\n",
    "\n",
    "# Show the prediction on a plot\n",
    "plt.plot(X_train[\"x\"], y_train, 'o', label=\"data\")\n",
    "plt.plot(X_train[\"x\"], y_pred_train, 'o', label=\"prediction\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Score the model\n",
    "print(\"Score train=\",my_model.score(X_train, y_train))\n",
    "print(\"Score test=\",my_model.score(X_test, y_test))\n",
    "\n",
    "# Get Feature Importance from the regression\n",
    "feature_importance_regressor = regressor.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIKIT - MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation + cross-split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cv_scores = []\n",
    "neighbors = np.arange(1, 15, 1)\n",
    "\n",
    "for i in neighbors:\n",
    "    scores = cross_val_score(KNeighborsClassifier(n_neighbors=i), X_train, y_train, cv=5)\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "best_n_neighbors = neighbors[np.argmax(cv_scores)]\n",
    "print(\"best CV score {:.3f}\".format(np.max(cv_scores)))\n",
    "print(\"best n_neighbors:\", best_n_neighbors)\n",
    "\n",
    "# Grid Searches pour SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "param_grid = {'hyper_parameter_1': np.arange(1, X_train.shape[1]+1),'hyper_parameter_2': [10, 50, 100, 250, 500]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, verbose=3, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.predict(X_test)\n",
    "\n",
    "grid_search.score(X_test, y_test)\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_\n",
    "grid_search.best_estimator_\n",
    "\n",
    "# NB: créer une dataframe pd pour analyser les résultats\n",
    "scores = pd.DataFrame(grid_search.cv_results_)\n",
    "scores.groupby(\"the_parameter\").mean().plot(y=[\"mean_train_score\", \"mean_test_score\"], logx=True)\n",
    "\n",
    "# Grid Searches pour Kneigh\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 15)}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=3, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best n_neighbors:\", grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
